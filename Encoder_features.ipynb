{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ventTools\n",
    "from ventTools.data import convert_to_fixed_length\n",
    "from ast import literal_eval\n",
    "import ventmode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining features of record\n",
    "@tf.function \n",
    "def map_fn(serialized_example):\n",
    "    feature = {\n",
    "        'label'                 : tf.io.FixedLenFeature(1, tf.int64),\n",
    "        'flow'                  : tf.io.FixedLenFeature(202, tf.float32),\n",
    "        'pressure'              : tf.io.FixedLenFeature(202, tf.float32),\n",
    "        'y'                     : tf.io.FixedLenFeature(1, tf.float32),\n",
    "        #'volume'                : tf.io.FixedLenFeature(200, tf.float32),\n",
    "        #'flow_diff'             : tf.io.FixedLenFeature(200, tf.float32),\n",
    "        #'pressure_diff'         : tf.io.FixedLenFeature(200, tf.float32),\n",
    "        #'flow_1lag'             : tf.io.FixedLenFeature(200, tf.float32),\n",
    "        #'flow_2lag'             : tf.io.FixedLenFeature(200, tf.float32),\n",
    "        #'flow_3lag'             : tf.io.FixedLenFeature(200, tf.float32),\n",
    "        #'pressure_1lag'         : tf.io.FixedLenFeature(200, tf.float32),\n",
    "        #'pressure_2lag'         : tf.io.FixedLenFeature(200, tf.float32),\n",
    "        #'pressure_3lag'         : tf.io.FixedLenFeature(200, tf.float32),\n",
    "        #'flow_1oracle'          : tf.io.FixedLenFeature(200, tf.float32),\n",
    "        #'flow_2oracle'          : tf.io.FixedLenFeature(200, tf.float32),\n",
    "        #'flow_3oracle'          : tf.io.FixedLenFeature(200, tf.float32),\n",
    "        #'pressure_1oracle'      : tf.io.FixedLenFeature(200, tf.float32),\n",
    "        #'pressure_2oracle'      : tf.io.FixedLenFeature(200, tf.float32),\n",
    "        #'pressure_3oracle'      : tf.io.FixedLenFeature(200, tf.float32),\n",
    "        #'flow_cumsum'           : tf.io.FixedLenFeature(200, tf.float32),\n",
    "        #'pressure_cumsum'       : tf.io.FixedLenFeature(200, tf.float32),        \n",
    "    }\n",
    "    return tf.io.parse_single_example(serialized_example, feature)\n",
    "\n",
    "@tf.function \n",
    "def map_all(serialized):\n",
    "    ex = map_fn(serialized)\n",
    "    return (tf.stack([ex[\"flow\"], ex[\"pressure\"]],1), ex[\"y\"]) \n",
    "                        #ex['volume'], \n",
    "                        #ex['flow_diff'], ex['pressure_diff'], \n",
    "                        #ex['flow_1lag'], ex['flow_2lag'], ex['flow_3lag'], \n",
    "                        #ex['pressure_1lag'], ex['pressure_2lag'], ex['pressure_3lag'], \n",
    "                        #ex['flow_1oracle'], ex['flow_2oracle'], ex['flow_3oracle'], \n",
    "                        #ex['pressure_1oracle'], ex['pressure_2oracle'], ex['pressure_3oracle'], ex['flow_cumsum'], ex['pressure_cumsum']], 1), ex[\"y\"])\n",
    "  \n",
    "\n",
    "@tf.function\n",
    "def get_dist(targets, n_classes, window_size):\n",
    "  shape = (n_classes,)\n",
    "  res = tf.zeros(shape)\n",
    "\n",
    "  for i in range(window_size):\n",
    "    idx = tf.gather(targets, i, axis=0)\n",
    "    mat = tf.sparse.SparseTensor([[idx]], [1.], shape)\n",
    "    res = tf.sparse.add(res, mat)\n",
    "    \n",
    "  res = tf.math.divide(res, window_size)\n",
    "  return tf.ensure_shape(res, shape)\n",
    "\n",
    "@tf.function\n",
    "def map_window(ds, window_size, input_shape):\n",
    "  feat = tf.zeros([0] + list(input_shape))\n",
    "  y = tf.zeros([0, ])\n",
    "  \n",
    "  for sample in ds:\n",
    "    ex = map_all(sample)\n",
    "\n",
    "    features = ex[0]\n",
    "    features = tf.convert_to_tensor(features)\n",
    "    features = tf.expand_dims(features, axis=0)\n",
    "\n",
    "    feat = tf.concat([feat, features], axis=0)\n",
    "    y = tf.concat([y, ex[1]], axis=0)\n",
    "    \n",
    "  feat = tf.ensure_shape(feat, (window_size, 200, 17))\n",
    "  y = tf.ensure_shape(y, (window_size,))\n",
    "  return (feat, y)\n",
    "\n",
    "\n",
    "window_size = 10\n",
    "x_shape = (200, 19)\n",
    "n_classes = 5\n",
    "calc_dist = lambda x, y: (x, get_dist(y, n_classes, window_size))\n",
    "\n",
    "train_set = tf.data.TFRecordDataset('train_raw.tfrecord')\n",
    "train_set = train_set.map(map_all)\n",
    "\n",
    "\n",
    "test_dataset = tf.data.TFRecordDataset('test_raw.tfrecord')\n",
    "test_dataset = test_dataset.map(map_all)\n",
    "\n",
    "train_size = sum(1 for _ in train_set)\n",
    "\n",
    "transpose_set = train_set.map(lambda x,y : (tf.transpose(x),y))\n",
    "\n",
    "transpose_test_set = test_dataset.map(lambda x,y : (tf.transpose(x),y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(file_no_ext, data_set, fileName):\n",
    "    json_file = open(file_no_ext + \".json\", 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = keras.models.model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(file_no_ext + \".h5\")\n",
    "    \n",
    "    # removemlp\n",
    "    model = keras.Sequential([\n",
    "        loaded_model.layers[0]\n",
    "    ])\n",
    "    model.build(input_shape = (None,2,202))\n",
    "    \n",
    "    # get prediction\n",
    "    features = [y for y in model.predict(data_set.batch(128))] \n",
    "    result = pd.DataFrame(features)\n",
    "    y_val = [y.numpy()[0] for _,y in data_set]\n",
    "    y_series = pd.Series(y_val)\n",
    "    \n",
    "    from pathlib import Path\n",
    "    file = Path(fileName)\n",
    "    result[\"y\"] = y_series\n",
    "\n",
    "    # save results to csv or another format\n",
    "\n",
    "    result.to_csv(file)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get features from transformer\n",
    "def encodeT(file_no_ext, data_set, fileName):\n",
    "    json_file = open(file_no_ext + \".json\", 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = keras.models.model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(file_no_ext + \".h5\")\n",
    "    print(loaded_model.layers[12])\n",
    "\n",
    "    model = keras.Model(loaded_model.layers[0].input, loaded_model.layers[12].output)\n",
    "    \n",
    "    # get prediction\n",
    "    features = [y for y in model.predict(data_set.batch(128))] \n",
    "    result = pd.DataFrame(features)\n",
    "    y_val = [y.numpy()[0] for _,y in data_set]\n",
    "    y_series = pd.Series(y_val)\n",
    "    \n",
    "    # save results to csv or another format\n",
    "    from pathlib import Path\n",
    "    file = Path(fileName)\n",
    "    result[\"y\"] = y_series\n",
    "\n",
    "    result.to_csv(file)\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodeT(\"transformer_cross2\", train_set, \"transformer_train_cross2\")\n",
    "encodeT(\"transformer_cross2\", test_dataset, \"transformer_test_cross2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode(\"lstm_model_cross2\", transpose_set, \"lstm_train_cross2\")\n",
    "encode(\"lstm_model_cross2\", transpose_test_set, \"lstm_test_cross2\")\n",
    "\n",
    "encode(\"conv_model_cross2\",transpose_set, \"cnn_train_cross2\")\n",
    "encode(\"conv_model_cross2\",transpose_test_set, \"cnn_test_cross2\")\n",
    "\n",
    "encode(\"ff_model_cross2\", transpose_set, \"ff_train_cross2\")\n",
    "encode(\"ff_model_cross2\", transpose_test_set, \"ff_test_cross2\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "687c238b3ce093b6d05593c14198ba6d4a27c356ca33aff629c1e2e7517a29f8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
