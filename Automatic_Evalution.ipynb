{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAZf5-l4Afpf"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/hahnicity/ventmode\n",
        "!python3 -m pip install ./ventmode\n",
        "!python -m pip install git+https://github.com/lukauskas/dtwco.git#egg=dtwco\n",
        "!git clone https://github.com/Villiamfj/ventTools\n",
        "%pip install -e ventTools tensorflow_decision_forests\n",
        "%pip install -q -U keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EQsVU4qB5YP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ventTools\n",
        "from ventTools.data import convert_to_fixed_length\n",
        "from ast import literal_eval\n",
        "import tensorflow_decision_forests as tfdf\n",
        "import ventmode\n",
        "from ventmode import datasets\n",
        "from os.path import join"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W214yTldvpUz"
      },
      "source": [
        "# Test Ventmode Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "\n",
        "def evaluate(y_true, y_pred):\n",
        "  print(classification_report(y_true, y_pred))\n",
        "  print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "def evaluate_clf(clf, clf_name, X_train, y_train, X_test, y_test):\n",
        "  print(f'=========== {clf_name} ===========')\n",
        "  clf = clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  evaluate(y_test, y_pred)\n",
        "  print('===========================')\n",
        "\n",
        "def evaluate_clfs(train_path, test_path):\n",
        "  train = pd.read_csv(train_path, index_col=0)\n",
        "  test = pd.read_csv(test_path, index_col=0)\n",
        "\n",
        "  y_train, y_test = train['y'], test['y']\n",
        "  X_train, X_test = train.drop(['y'], axis=1), test.drop(['y'], axis=1)\n",
        "\n",
        "  X_copy, y_copy = X_train.copy(), y_train.copy()\n",
        "  X_test_copy, y_test_copy = X_test.copy(), y_test.copy()\n",
        "\n",
        "  print(\"=========== DATA ===========\")\n",
        "  print(X_train, y_train)\n",
        "  print('===========================')\n",
        "  log_reg = LogisticRegression(penalty='l2', C=4,tol=.0001, solver='lbfgs')\n",
        "  rf = RandomForestClassifier(max_features='auto', n_estimators=30, max_depth=15, criterion='entropy', random_state=2)\n",
        "  mlp = MLPClassifier(activation='tanh', learning_rate_init = 0.01, solver = 'adam', hidden_layer_sizes = [64, 32])\n",
        "  svm = LinearSVC(C=10)\n",
        "\n",
        "  evaluate_clf(log_reg, 'LogisticRegression', X_train, y_train, X_test, y_test)\n",
        "  evaluate_clf(rf, 'RandomForest', X_train, y_train, X_test, y_test)\n",
        "  evaluate_clf(mlp, 'MultiLayerPerceptron', X_train, y_train, X_test, y_test)\n",
        "  evaluate_clf(svm, 'Support Vector Classification', X_train, y_train, X_test, y_test)\n"
      ],
      "metadata": {
        "id": "6WSLyxHSInkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\" <<======== CNN =========>> \")\n",
        "evaluate_clfs('cnn_train_cross2', 'cnn_test_cross2')\n",
        "print('===========================')\n",
        "print(\" <<======== MLP =========>> \")\n",
        "evaluate_clfs('ff_train_cross2', 'ff_test_cross2')\n",
        "print('===========================')\n",
        "print(\" <<======== LSTM =========>> \")\n",
        "evaluate_clfs('lstm_train_cross2', 'lstm_test_cross2')\n",
        "print('===========================')\n",
        "print(\" <<======== Transformer =========>> \")\n",
        "evaluate_clfs('transformer_train_cross2', 'transformer_test_cross2')\n",
        "print('===========================')\n"
      ],
      "metadata": {
        "id": "d-lWyuVe5c4_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "kVUQT69rELXp",
        "kbFjPzQtGL3M",
        "d4itLiQeHyOB",
        "TN5f6J2BH5iE"
      ],
      "name": "Automatic Evalution.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}