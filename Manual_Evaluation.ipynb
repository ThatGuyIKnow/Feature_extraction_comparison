{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAZf5-l4Afpf"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/hahnicity/ventmode\n",
        "!python3 -m pip install ./ventmode\n",
        "!python -m pip install git+https://github.com/lukauskas/dtwco.git#egg=dtwco\n",
        "!git clone https://github.com/Villiamfj/ventTools\n",
        "%pip install -e ventTools tensorflow_decision_forests\n",
        "%pip install -q -U keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EQsVU4qB5YP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ventTools\n",
        "from ventTools.data import convert_to_fixed_length\n",
        "from ast import literal_eval\n",
        "import ventmode\n",
        "from ventmode import datasets\n",
        "from os.path import join\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W214yTldvpUz"
      },
      "source": [
        "# Test Ventmode Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLLDFHNopBV3"
      },
      "outputs": [],
      "source": [
        "mode_to_index = {\n",
        "    0: 0, \n",
        "    1: 1, \n",
        "    3: 2, \n",
        "    4: 3, \n",
        "    6: 4\n",
        "}\n",
        "\n",
        "vfinal_features = [\n",
        "    #\"itime_var_max_win\",#\n",
        "    #\"maw_var\",#\n",
        "    \"flow_var_var\",\n",
        "    \"all_pressure_var\",\n",
        "    \"flow_var\",\n",
        "    #\"pip_min_peep\",#\n",
        "    #\"tvi_var\",#\n",
        "    #\"pressure_var\",#\n",
        "    \"itime_var\",\n",
        "    \"pressure_itime_var\",\n",
        "    \"pressure_itime_var_max_win\",\n",
        "    \"n_plats_past_20\",\n",
        "    #'median_peep',#\n",
        "    #'median_pip',#\n",
        "    #'ipauc:epauc',#\n",
        "]\n",
        "\n",
        "def test_ventmode_dataset(df, classifer, metrics, label='y'):\n",
        "  test_df = df.copy()\n",
        "\n",
        "  #test_feat = test_df[vfinal_features + [label]]\n",
        "  test_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(test_feat, label = label)\n",
        "  \n",
        "  classifer.compile(metrics=metrics)\n",
        "  classifer.evaluate(test_dataset)\n",
        "\n",
        "\n",
        "def _get_df(fileset):\n",
        "  vfinal = datasets.VFinalFeatureSet(fileset, 10, 100)\n",
        "  df = vfinal.create_learning_df()\n",
        "\n",
        "  df = df[df['y'].isin(mode_to_index.keys())]\n",
        "  df['y'] = df['y'].apply(lambda x: mode_to_index[x])\n",
        "\n",
        "  df = df.select_dtypes(include=[np.number])\n",
        "  df = df[~df.isin([np.nan, np.inf, -np.inf]).any(1)]\n",
        "\n",
        "  return df[df.columns.difference(['y', 'rel_bn', 'vent_bn', 'idx', 'x0_idx'])], df[['y']]\n",
        "\n",
        "\n",
        "def get_train_df():\n",
        "  COHORT_X_DIR = join(\"ventmode/anon_train_data\", \"raw_vwd\")\n",
        "  COHORT_Y_DIR = join(\"ventmode/anon_train_data\", \"y_dir\")\n",
        "  fileset = datasets.get_cohort_fileset(COHORT_X_DIR, COHORT_Y_DIR)\n",
        "  return _get_df(fileset)\n",
        "\n",
        "\n",
        "def get_test_df():\n",
        "  TEST_COHORT_X_DIR = join(\"ventmode/anon_test_data\", \"raw_vwd\")\n",
        "  TEST_COHORT_Y_DIR = join(\"ventmode/anon_test_data\", \"y_dir\")\n",
        "  test_fileset = datasets.get_cohort_fileset(TEST_COHORT_X_DIR, TEST_COHORT_Y_DIR)\n",
        "  return _get_df(test_fileset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VS91-HVip9k8"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = get_train_df()\n",
        "X_test, y_test = get_test_df()\n",
        "\n",
        "\n",
        "X_all_copy, y_all_copy = X_train.copy(), y_train.copy()\n",
        "X_test_all_copy, y_test_all_copy = X_test.copy(), y_test.copy()\n",
        "# X_train = X_train[vfinal_features]\n",
        "# X_test = X_test[vfinal_features]\n",
        "\n",
        "X_copy, y_copy = X_train.copy(), y_train.copy()\n",
        "X_test_copy, y_test_copy = X_test.copy(), y_test.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgxHPK0mLU6b"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "X_train, y_train = X_copy.copy(), y_copy.copy()\n",
        "X_test, y_test = X_test_copy.copy(), y_test_copy.copy()\n",
        "\n",
        "\n",
        "scaler = RobustScaler()\n",
        "cols = X_train.columns\n",
        "train_index = X_train.index\n",
        "test_index = X_test.index\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "if len(X_test) != 0:\n",
        "    X_test = scaler.transform(X_test)\n",
        "X_train, X_test = pd.DataFrame(X_train, index=train_index, columns=cols), pd.DataFrame(X_test, index=test_index, columns=cols)\n",
        "\n",
        "X_copy, y_copy = X_train.copy(), y_train.copy()\n",
        "X_test_copy, y_test_copy = X_test.copy(), y_test.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDU1MHQTXCqX"
      },
      "outputs": [],
      "source": [
        "def evaluate(y_true, y_pred):\n",
        "  print(classification_report(y_true, y_pred))\n",
        "  print(confusion_matrix(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2GpAB5rUMO0"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_train, y_train = X_copy.copy(), y_copy.copy()\n",
        "X_test, y_test = X_test_copy.copy(), y_test_copy.copy()\n",
        "\n",
        "\n",
        "clf = LinearSVC(C=10)\n",
        "clf = clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "evaluate(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gm4_NMQ31tvg"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "\n",
        "X_train, y_train = X_copy.copy(), y_copy.copy()\n",
        "X_test, y_test = X_test_copy.copy(), y_test_copy.copy()\n",
        "\n",
        "\n",
        "clf = MLPClassifier(activation='tanh', learning_rate_init = 0.01, solver = 'adam', hidden_layer_sizes = [64, 32])\n",
        "clf = clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "evaluate(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTefouiUWRP1"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow_decision_forests as tfdf\n",
        "\n",
        "X_train, y_train = X_copy.copy(), y_copy.copy()\n",
        "X_test, y_test = X_test_copy.copy(), y_test_copy.copy()\n",
        "\n",
        "clf = RandomForestClassifier(max_features='auto', n_estimators=30, max_depth=15, criterion='entropy', random_state=1)\n",
        "clf = clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "evaluate(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWFymW6sU5ak"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_train, y_train = X_copy.copy(), y_copy.copy()\n",
        "X_test, y_test = X_test_copy.copy(), y_test_copy.copy()\n",
        "\n",
        "clf = LogisticRegression(penalty='l2', C=4,tol=.0001, solver='lbfgs')\n",
        "clf = clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "evaluate(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding target length"
      ],
      "metadata": {
        "id": "yddi3vg9wp5c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1sYrwY9Canc"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6-WIFLO8sWd"
      },
      "outputs": [],
      "source": [
        "percentages = [0.1, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 0.7, 0.75, 0.8, 0.9, 0.95]\n",
        "quantiles = X_train['breath_time'].quantile(percentages)\n",
        "quantiles / 0.02"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZXU69bf-hhL"
      },
      "outputs": [],
      "source": [
        "samples = X_train['breath_time'] / 0.02\n",
        "samples.hist(bins=20)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "kVUQT69rELXp",
        "kbFjPzQtGL3M",
        "d4itLiQeHyOB",
        "TN5f6J2BH5iE"
      ],
      "name": "Manual Evaluation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}